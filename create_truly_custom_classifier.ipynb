{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed3751a-6dca-4a47-8544-7ed2b78b7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 09:42:49.126471: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-23 09:42:49.126548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-23 09:42:49.126568: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-23 09:42:49.206007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import collections\n",
    "from etils import epath\n",
    "from ml_collections import config_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from chirp import audio_utils\n",
    "from chirp.inference import a2o_utils\n",
    "from chirp.inference import interface\n",
    "from chirp.inference import tf_examples\n",
    "from chirp.inference import models\n",
    "from chirp.models import metrics\n",
    "from chirp.taxonomy import namespace\n",
    "from chirp.inference.search import bootstrap\n",
    "from chirp.inference.search import search\n",
    "from chirp.inference.search import display\n",
    "from chirp.inference.classify import classify\n",
    "from chirp.inference.classify import data_lib\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "from scipy.io import wavfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331ac4f7-3376-4ce8-b641-8b0c121cf270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 09:44:35.032799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15381 MB memory:  -> device: 0, name: Quadro GP100, pci bus id: 0000:5b:00.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# load embedding config\n",
    "working_dir =  '.'\n",
    "embeddings_path = epath.Path(working_dir) / 'embeddings_all'\n",
    "labeled_data_path = epath.Path(working_dir) / 'labeled_outputs'\n",
    "custom_classifier_path = epath.Path(working_dir) / 'custom_classifier'\n",
    "bootstrap_config = bootstrap.BootstrapConfig.load_from_embedding_path(\n",
    "      embeddings_path=embeddings_path,\n",
    "      annotated_path=labeled_data_path)\n",
    "\n",
    "project_state = bootstrap.BootstrapState(\n",
    "    bootstrap_config, a2o_auth_token='')\n",
    "window_s = bootstrap_config.model_config['window_size_s']\n",
    "sample_rate = bootstrap_config.model_config['sample_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5af1bc-3a6b-4b18-90bc-8f79355bfd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding from Folder of Folders...\n",
      "Checking for existing embeddings from Folder of Folders...\n",
      "Found 0 existing embeddings.\n",
      "Checking for new sources to embed from Folder of Folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 09:45:02.953672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b285eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-23 09:45:02.953736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro GP100, Compute Capability 6.0\n",
      "2024-06-23 09:45:04.133691: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-23 09:45:04.186901: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "2024-06-23 09:45:08.781494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-06-23 09:45:18.255793: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "1it [00:22, 22.48s/it]\n",
      "1it [00:00, 11.49it/s]\n",
      "14it [00:00, 59.89it/s]\n",
      "13it [00:00, 71.41it/s]\n",
      "2it [00:00, 19.40it/s]\n",
      "14it [00:00, 70.37it/s]\n",
      "15it [00:00, 57.31it/s]\n",
      "13it [00:00, 66.29it/s]\n",
      "13it [00:00, 71.28it/s]\n",
      "22it [00:00, 63.84it/s]\n",
      "12it [00:00, 61.93it/s]\n",
      "6it [00:00, 66.91it/s]\n",
      "23it [00:00, 65.29it/s]\n",
      "31it [00:00, 77.41it/s]\n",
      "2it [00:00, 21.00it/s]\n",
      "6it [00:00, 50.45it/s]\n",
      "33it [00:00, 77.84it/s]\n",
      "36it [00:00, 84.08it/s]\n",
      "21it [00:00, 72.89it/s]\n",
      "8it [00:00, 58.28it/s]\n",
      "14it [00:00, 71.53it/s]\n",
      "22it [00:00, 81.16it/s]\n",
      "16it [00:00, 65.93it/s]\n",
      "22it [00:00, 81.22it/s]\n",
      "21it [00:00, 34.28it/s]\n",
      "26it [00:00, 80.90it/s]\n",
      "25it [00:00, 62.63it/s]\n",
      "9it [00:00, 59.19it/s]\n",
      "29it [00:00, 76.67it/s]\n",
      "11it [00:00, 50.52it/s]\n",
      "22it [00:00, 74.61it/s]\n",
      "14it [00:00, 65.33it/s]\n",
      "44it [00:00, 87.40it/s]\n",
      "15it [00:00, 78.23it/s]\n",
      "16it [00:00, 67.22it/s]\n",
      "16it [00:00, 58.55it/s]\n",
      "25it [00:00, 65.11it/s]\n",
      "27it [00:00, 64.97it/s]\n",
      "1it [00:00, 11.17it/s]\n",
      "16it [00:00, 66.78it/s]\n",
      "8it [00:00, 50.74it/s]\n",
      "17it [00:00, 68.03it/s]\n",
      "8it [00:00, 54.04it/s]\n",
      "34it [00:00, 72.36it/s]\n",
      "17it [00:00, 53.28it/s]\n",
      "27it [00:00, 65.61it/s]\n",
      "13it [00:00, 49.31it/s]\n",
      "24it [00:00, 77.48it/s]\n",
      "36it [00:00, 81.57it/s]\n",
      "45it [00:00, 80.35it/s]\n",
      "15it [00:00, 62.07it/s]\n",
      "26it [00:00, 68.91it/s]\n",
      "29it [00:00, 81.62it/s]\n",
      "1it [00:00, 16.18it/s]\n",
      "15it [00:00, 71.77it/s]\n",
      "9it [00:00, 64.54it/s]\n",
      "2it [00:00, 22.96it/s]\n",
      "48it [00:00, 84.78it/s]\n",
      "17it [00:00, 29.62it/s]\n",
      "13it [00:00, 60.97it/s]\n",
      "10it [00:00, 58.13it/s]\n",
      "12it [00:00, 55.57it/s]\n",
      "20it [00:00, 68.64it/s]\n",
      "14it [00:00, 56.02it/s]\n",
      "16it [00:00, 59.04it/s]\n",
      "21it [00:00, 58.60it/s]\n",
      "14it [00:00, 53.05it/s]\n",
      "23it [00:00, 66.94it/s]\n",
      "24it [00:00, 57.57it/s]\n",
      "15it [00:00, 55.21it/s]\n",
      "157it [00:01, 83.05it/s]\n",
      "6it [00:00, 54.15it/s]\n",
      "15it [00:00, 75.15it/s]\n",
      "15it [00:00, 56.35it/s]\n",
      "26it [00:00, 76.08it/s]\n",
      "13it [00:00, 62.01it/s]\n",
      "43it [00:00, 85.09it/s]\n",
      "17it [00:00, 68.83it/s]\n",
      "27it [00:00, 83.13it/s]\n",
      "26it [00:00, 59.46it/s]\n",
      "10it [00:00, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...embedded dataset in 46.81s...\n",
      "    found 81 classes.\n",
      "    class amedip_call / 0 : 1\n",
      "    class amekes_call / 1 : 1\n",
      "    class amerob_call / 2 : 14\n",
      "    class amerob_song / 3 : 13\n",
      "    class annhum_song / 4 : 2\n",
      "    class bkbwoo_call / 5 : 14\n",
      "    class bkhgro_call / 6 : 15\n",
      "    class bkhgro_song / 7 : 13\n",
      "    class brncre_call / 8 : 13\n",
      "    class brncre_song / 9 : 22\n",
      "    class btywar_song / 10 : 12\n",
      "    class casfin_call / 11 : 6\n",
      "    class casfin_song / 12 : 23\n",
      "    class casvir_song / 13 : 31\n",
      "    class chispa_song / 14 : 2\n",
      "    class clanut_call / 15 : 6\n",
      "    class comnig_call / 16 : 33\n",
      "    class compoo_song / 17 : 36\n",
      "    class comrav_call / 18 : 21\n",
      "    class coohaw_call / 19 : 8\n",
      "    class coohaw_song / 20 : 14\n",
      "    class daejun_call / 21 : 22\n",
      "    class daejun_song / 22 : 16\n",
      "    class dusfly_call / 23 : 22\n",
      "    class dusfly_song / 24 : 21\n",
      "    class evegro_call / 25 : 26\n",
      "    class flaowl_song / 26 : 25\n",
      "    class foxspa_song / 27 : 9\n",
      "    class gnttow_call / 28 : 29\n",
      "    class gnttow_song / 29 : 11\n",
      "    class gockin_call / 30 : 22\n",
      "    class gockin_song / 31 : 14\n",
      "    class haiwoo_call / 32 : 44\n",
      "    class haiwoo_song / 33 : 15\n",
      "    class hamfly_song / 34 : 16\n",
      "    class herthr_call / 35 : 16\n",
      "    class herthr_song / 36 : 25\n",
      "    class herwar_song / 37 : 27\n",
      "    class houfin_call / 38 : 1\n",
      "    class houwre_song / 39 : 16\n",
      "    class lazbun_call / 40 : 8\n",
      "    class lazbun_song / 41 : 17\n",
      "    class linspa_song / 42 : 8\n",
      "    class macwar_call / 43 : 34\n",
      "    class macwar_song / 44 : 17\n",
      "    class moublu_call / 45 : 27\n",
      "    class mouchi_call / 46 : 13\n",
      "    class mouchi_song / 47 : 24\n",
      "    class mouqua_call / 48 : 36\n",
      "    class naswar_song / 49 : 45\n",
      "    class norfli_call / 50 : 15\n",
      "    class norfli_song / 51 : 26\n",
      "    class olsfly_song / 52 : 29\n",
      "    class pacwre1_call / 53 : 1\n",
      "    class pacwre1_song / 54 : 15\n",
      "    class pilwoo_call / 55 : 9\n",
      "    class pingro_call / 56 : 2\n",
      "    class rebnut_call / 57 : 48\n",
      "    class rebsap_call / 58 : 17\n",
      "    class redcro_call / 59 : 13\n",
      "    class rethaw_call / 60 : 10\n",
      "    class rocwre_call / 61 : 12\n",
      "    class rocwre_song / 62 : 20\n",
      "    class sonspa_call / 63 : 14\n",
      "    class soogro1_song / 64 : 16\n",
      "    class spotow_call / 65 : 21\n",
      "    class spotow_song / 66 : 14\n",
      "    class stejay_call / 67 : 23\n",
      "    class towsol_call / 68 : 24\n",
      "    class towsol_song / 69 : 15\n",
      "    class unknown / 70 : 157\n",
      "    class vauswi_call / 71 : 6\n",
      "    class warvir_song / 72 : 15\n",
      "    class wesblu_call / 73 : 15\n",
      "    class westan_call / 74 : 26\n",
      "    class westan_song / 75 : 13\n",
      "    class wewpew_call / 76 : 43\n",
      "    class whbnut_call / 77 : 17\n",
      "    class whhwoo_call / 78 : 27\n",
      "    class yerwar_call / 79 : 26\n",
      "    class yerwar_song / 80 : 10\n",
      "num classes : 81\n",
      "mean ex / class : 19.814814814814813\n",
      "min ex / class : 1.0\n"
     ]
    }
   ],
   "source": [
    "# load embedding, train smaller model\n",
    "\n",
    "merged = data_lib.MergedDataset.from_folder_of_folders(\n",
    "    base_dir=labeled_data_path,\n",
    "    embedding_model=project_state.embedding_model,\n",
    "    time_pooling='mean',\n",
    "    load_audio=False,\n",
    "    target_sample_rate=sample_rate,\n",
    "    audio_file_pattern='*',\n",
    "    embedding_config_hash=bootstrap_config.embedding_config_hash(),\n",
    ")\n",
    "\n",
    "lbl_counts = np.sum(merged.data['label_hot'], axis=0)\n",
    "print('num classes :', (lbl_counts > 0).sum())\n",
    "print('mean ex / class :', lbl_counts.sum() / (lbl_counts > 0).sum())\n",
    "print('min ex / class :', (lbl_counts + (lbl_counts == 0) * 1e6).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b72c7f-1053-4d19-b010-17655510b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]2024-06-23 09:46:29.803124: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8981802564530550995\n",
      "2024-06-23 09:46:29.803238: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6357226189113289516\n",
      "2024-06-23 09:48:53.883768: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7458827095098341151\n",
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      " 33%|███▎      | 1/3 [02:33<05:06, 153.29s/it]2024-06-23 09:48:59.503618: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8981802564530550995\n",
      "2024-06-23 09:48:59.503720: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6357226189113289516\n",
      "2024-06-23 09:48:59.503760: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14969174540760464816\n",
      "2024-06-23 09:48:59.503774: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 16209690060479520002\n",
      "2024-06-23 09:51:21.477772: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7458827095098341151\n",
      " 67%|██████▋   | 2/3 [04:57<02:27, 147.81s/it]2024-06-23 09:51:23.502086: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8981802564530550995\n",
      "2024-06-23 09:51:23.502168: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 10448846825707801487\n",
      "2024-06-23 09:51:23.502189: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6357226189113289516\n",
      "2024-06-23 09:51:23.502222: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14969174540760464816\n",
      "2024-06-23 09:53:46.773978: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7458827095098341151\n",
      "100%|██████████| 3/3 [07:22<00:00, 147.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.93, auc_roc: 1.00, cmap: 0.83\n",
      "\n",
      "amerob_call, auc_roc: 1.00\n",
      "\n",
      "amerob_song, auc_roc: 1.00\n",
      "\n",
      "bkbwoo_call, auc_roc: 1.00\n",
      "\n",
      "bkhgro_call, auc_roc: 1.00\n",
      "\n",
      "bkhgro_song, auc_roc: 1.00\n",
      "\n",
      "brncre_call, auc_roc: 1.00\n",
      "\n",
      "brncre_song, auc_roc: 1.00\n",
      "\n",
      "btywar_song, auc_roc: 1.00\n",
      "\n",
      "casfin_song, auc_roc: 1.00\n",
      "\n",
      "casvir_song, auc_roc: 1.00\n",
      "\n",
      "comnig_call, auc_roc: 1.00\n",
      "\n",
      "compoo_song, auc_roc: 1.00\n",
      "\n",
      "comrav_call, auc_roc: 1.00\n",
      "\n",
      "coohaw_song, auc_roc: 1.00\n",
      "\n",
      "daejun_call, auc_roc: 1.00\n",
      "\n",
      "daejun_song, auc_roc: 1.00\n",
      "\n",
      "dusfly_call, auc_roc: 1.00\n",
      "\n",
      "dusfly_song, auc_roc: 1.00\n",
      "\n",
      "evegro_call, auc_roc: 1.00\n",
      "\n",
      "flaowl_song, auc_roc: 1.00\n",
      "\n",
      "gnttow_call, auc_roc: 1.00\n",
      "\n",
      "gnttow_song, auc_roc: 1.00\n",
      "\n",
      "gockin_call, auc_roc: 1.00\n",
      "\n",
      "gockin_song, auc_roc: 1.00\n",
      "\n",
      "haiwoo_call, auc_roc: 1.00\n",
      "\n",
      "haiwoo_song, auc_roc: 1.00\n",
      "\n",
      "hamfly_song, auc_roc: 1.00\n",
      "\n",
      "herthr_call, auc_roc: 1.00\n",
      "\n",
      "herthr_song, auc_roc: 1.00\n",
      "\n",
      "herwar_song, auc_roc: 1.00\n",
      "\n",
      "houwre_song, auc_roc: 1.00\n",
      "\n",
      "lazbun_song, auc_roc: 1.00\n",
      "\n",
      "macwar_call, auc_roc: 0.99\n",
      "\n",
      "macwar_song, auc_roc: 1.00\n",
      "\n",
      "moublu_call, auc_roc: 1.00\n",
      "\n",
      "mouchi_call, auc_roc: 1.00\n",
      "\n",
      "mouchi_song, auc_roc: 1.00\n",
      "\n",
      "mouqua_call, auc_roc: 1.00\n",
      "\n",
      "naswar_song, auc_roc: 1.00\n",
      "\n",
      "norfli_call, auc_roc: 1.00\n",
      "\n",
      "norfli_song, auc_roc: 1.00\n",
      "\n",
      "olsfly_song, auc_roc: 1.00\n",
      "\n",
      "pacwre1_song, auc_roc: 1.00\n",
      "\n",
      "rebnut_call, auc_roc: 1.00\n",
      "\n",
      "rebsap_call, auc_roc: 1.00\n",
      "\n",
      "redcro_call, auc_roc: 1.00\n",
      "\n",
      "rethaw_call, auc_roc: 1.00\n",
      "\n",
      "rocwre_call, auc_roc: 1.00\n",
      "\n",
      "rocwre_song, auc_roc: 1.00\n",
      "\n",
      "sonspa_call, auc_roc: 1.00\n",
      "\n",
      "soogro1_song, auc_roc: 1.00\n",
      "\n",
      "spotow_call, auc_roc: 1.00\n",
      "\n",
      "spotow_song, auc_roc: 1.00\n",
      "\n",
      "stejay_call, auc_roc: 1.00\n",
      "\n",
      "towsol_call, auc_roc: 1.00\n",
      "\n",
      "towsol_song, auc_roc: 1.00\n",
      "\n",
      "unknown , auc_roc: 1.00\n",
      "\n",
      "warvir_song, auc_roc: 1.00\n",
      "\n",
      "wesblu_call, auc_roc: 1.00\n",
      "\n",
      "westan_call, auc_roc: 1.00\n",
      "\n",
      "westan_song, auc_roc: 0.99\n",
      "\n",
      "wewpew_call, auc_roc: 1.00\n",
      "\n",
      "whbnut_call, auc_roc: 1.00\n",
      "\n",
      "whhwoo_call, auc_roc: 1.00\n",
      "\n",
      "yerwar_call, auc_roc: 0.99\n",
      "\n",
      "yerwar_song, auc_roc: 1.00\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9 \n",
    "train_examples_per_class = None  \n",
    "\n",
    "num_seeds = 3\n",
    "\n",
    "# Classifier training hyperparams.\n",
    "# These should be good defaults.\n",
    "batch_size = 32\n",
    "num_epochs = 128\n",
    "num_hiddens = -1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "for seed in tqdm(range(num_seeds)):\n",
    "  if num_hiddens > 0:\n",
    "    model = classify.get_two_layer_model(\n",
    "        num_hiddens, merged.embedding_dim, merged.num_classes, True)\n",
    "  else:\n",
    "    model = classify.get_linear_model(\n",
    "        merged.embedding_dim, merged.num_classes)\n",
    "  run_metrics = classify.train_embedding_model(\n",
    "      model, merged, train_ratio, train_examples_per_class,\n",
    "      num_epochs, seed, batch_size, learning_rate)\n",
    "  metrics['acc'].append(run_metrics.top1_accuracy)\n",
    "  metrics['auc_roc'].append(run_metrics.auc_roc)\n",
    "  metrics['cmap'].append(run_metrics.cmap_value)\n",
    "  metrics['maps'].append(run_metrics.class_maps)\n",
    "  metrics['test_logits'].append(run_metrics.test_logits)\n",
    "\n",
    "mean_acc = np.mean(metrics['acc'])\n",
    "mean_auc = np.mean(metrics['auc_roc'])\n",
    "mean_cmap = np.mean(metrics['cmap'])\n",
    "# Merge the test_logits into a single array.\n",
    "test_logits = {\n",
    "    k: np.concatenate([logits[k] for logits in metrics['test_logits']])\n",
    "    for k in metrics['test_logits'][0].keys()\n",
    "}\n",
    "\n",
    "print(f'acc:{mean_acc:5.2f}, auc_roc:{mean_auc:5.2f}, cmap:{mean_cmap:5.2f}')\n",
    "for lbl, auc in zip(merged.labels, run_metrics.class_maps):\n",
    "  if np.isnan(auc):\n",
    "    continue\n",
    "  print(f'\\n{lbl:8s}, auc_roc:{auc:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5227023-e315-4bb0-b726-fa7b646da61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs/custom_classifier/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs/custom_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "# save model to outputs\n",
    "model.save(epath.Path(working_dir) / epath.Path('outputs') / 'custom_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89cd732-1504-48fc-96a7-fc8eca4a8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87135it [1:11:04, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "   Detection count:  1263169890\n",
      "NonDetection count:  0\n"
     ]
    }
   ],
   "source": [
    "output_filepath = epath.Path(working_dir) / epath.Path('outputs_all') / 'inference_custom.csv'\n",
    "\n",
    "class_thresholds = None # write all logits\n",
    "\n",
    "include_classes = [] # if empty, includes all classes\n",
    "exclude_classes = []\n",
    "\n",
    "embeddings_ds = project_state.create_embeddings_dataset(\n",
    "    shuffle_files=True)\n",
    "classify.write_inference_csv(\n",
    "    embeddings_ds=embeddings_ds,\n",
    "    model=model,\n",
    "    labels=merged.labels,\n",
    "    output_filepath=output_filepath,\n",
    "    threshold=class_thresholds,\n",
    "    embedding_hop_size_s=bootstrap_config.embedding_hop_size_s,\n",
    "    include_classes=include_classes,\n",
    "    exclude_classes=exclude_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4b41da-6f0f-4374-909f-48c77b6a3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = pd.read_csv(output_filepath, skipinitialspace=True) # annoying initial space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b208462-8d35-4789-8af0-996f33d37cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.to_parquet(epath.Path(working_dir) / epath.Path('outputs_all') / 'inference_custom.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
