{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e99e9a-11a4-4e70-b8c5-73e176bc8494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 15:49:09.900161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 15:49:09.900226: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 15:49:09.900238: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 15:49:09.937197: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from etils import epath\n",
    "from ml_collections import config_dict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from chirp import audio_utils\n",
    "from chirp.inference import embed_lib\n",
    "from chirp.inference import tf_examples\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437261b7-3373-4af4-a3d2-f3d18ef9ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 'perch'\n",
    "\n",
    "working_dir = '.'  \n",
    "\n",
    "\n",
    "embeddings_path = epath.Path(working_dir) / 'embeddings_all'\n",
    "labeled_data_path = epath.Path(working_dir) / 'labeled'\n",
    "embeddings_glob = embeddings_path / 'embeddings-*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d23ce3e-a3a8-4543-842f-f19d1b594c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_dict.ConfigDict()\n",
    "config.embed_fn_config = config_dict.ConfigDict()\n",
    "config.embed_fn_config.model_config = config_dict.ConfigDict()\n",
    "\n",
    "\n",
    "config.source_file_patterns = ['/home/mschulist/caples_sound/ARU_data_all/*/*.wav']\n",
    "config.output_dir = embeddings_path.as_posix()\n",
    "\n",
    "\n",
    "perch_tfhub_version = 8\n",
    "perch_model_path = ''\n",
    "\n",
    "config.embed_fn_config.model_key = 'taxonomy_model_tf'\n",
    "config.embed_fn_config.model_config.window_size_s = 5.0\n",
    "config.embed_fn_config.model_config.hop_size_s = 5.0\n",
    "config.embed_fn_config.model_config.sample_rate = 32000\n",
    "config.embed_fn_config.model_config.tfhub_version = perch_tfhub_version\n",
    "config.embed_fn_config.model_config.model_path = perch_model_path\n",
    "\n",
    "# Only write embeddings to reduce size.\n",
    "config.embed_fn_config.write_embeddings = True\n",
    "config.embed_fn_config.write_logits = False\n",
    "config.embed_fn_config.write_separated_audio = False\n",
    "config.embed_fn_config.write_raw_audio = False\n",
    "\n",
    "# Number of parent directories to include in the filename.\n",
    "config.embed_fn_config.file_id_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7908e5-c588-49b0-8d14-8aa4947d662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading model(s)...\n",
      "Found 87135 source infos.\n",
      "\n",
      "\n",
      "Test-run of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 15:55:38.802812: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Set up the embedding function, including loading models.\n",
    "embed_fn = embed_lib.EmbedFn(**config.embed_fn_config)\n",
    "print('\\n\\nLoading model(s)...')\n",
    "embed_fn.setup()\n",
    "\n",
    "# Create output directory and write the configuration.\n",
    "output_dir = epath.Path(config.output_dir)\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "embed_lib.maybe_write_config(config, output_dir)\n",
    "\n",
    "# Create SourceInfos.\n",
    "source_infos = embed_lib.create_source_infos(\n",
    "    config.source_file_patterns,\n",
    "    num_shards_per_file=config.get('num_shards_per_file', -1),\n",
    "    shard_len_s=config.get('shard_len_s', -1))\n",
    "print(f'Found {len(source_infos)} source infos.')\n",
    "\n",
    "print('\\n\\nTest-run of model...')\n",
    "window_size_s = config.embed_fn_config.model_config.window_size_s\n",
    "sr = config.embed_fn_config.model_config.sample_rate\n",
    "z = np.zeros([int(sr * window_size_s)])\n",
    "embed_fn.embedding_model.embed(z)\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a638f9-1abe-4a91-806e-dbcaec8b7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87135 existing embedding ids.Processing 87135 new source infos. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                 | 0/87135 [00:00<?, ?it/s]2024-06-20 15:56:21.214690: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "  0%|                                                                                    | 111/87135 [04:20<63:20:55,  2.62s/it]2024-06-20 16:00:29.909328: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "  2%|█▌                                                                                 | 1604/87135 [47:09<38:35:36,  1.62s/it]2024-06-20 16:43:17.789020: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "  2%|█▋                                                                                 | 1769/87135 [50:40<35:10:09,  1.48s/it]2024-06-20 16:46:49.081925: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "  5%|███▋                                                                             | 3948/87135 [1:35:27<25:05:00,  1.09s/it]2024-06-20 17:31:35.477514: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "  9%|███████▏                                                                         | 7725/87135 [2:52:13<25:28:40,  1.16s/it]2024-06-20 18:48:21.683564: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      " 19%|██████████████▉                                                                 | 16296/87135 [6:26:43<21:39:33,  1.10s/it]2024-06-20 22:22:51.920480: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      " 19%|███████████████▏                                                                | 16585/87135 [6:33:47<23:10:01,  1.18s/it]2024-06-20 22:29:55.647138: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      " 19%|███████████████▎                                                                | 16727/87135 [6:37:39<20:49:48,  1.07s/it]2024-06-20 22:33:47.466544: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      " 21%|████████████████▌                                                               | 18066/87135 [7:10:27<35:30:43,  1.85s/it]2024-06-20 23:06:35.947020: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      " 24%|██████████████████▉                                                             | 20595/87135 [8:11:54<18:45:04,  1.01s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|███████████████████████████████████████▊                                       | 43980/87135 [18:17:01<12:33:50,  1.05s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 69%|██████████████████████████████████████████████████████▎                        | 59951/87135 [24:47:23<18:06:42,  2.40s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████████████████████▉          | 76214/87135 [31:44:05<5:33:24,  1.83s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uses multiple threads to load audio before embedding.\n",
    "# This tends to be faster, but can fail if any audio files are corrupt.\n",
    "\n",
    "min_file_size = 10_000_000 # 10 MB\n",
    "\n",
    "\n",
    "embed_fn.min_audio_s = 1.0\n",
    "record_file = (output_dir / 'embeddings.tfrecord').as_posix()\n",
    "succ, fail = 0, 0\n",
    "\n",
    "existing_embedding_ids = embed_lib.get_existing_source_ids(\n",
    "    output_dir, 'embeddings-*')\n",
    "\n",
    "new_source_infos = embed_lib.get_new_source_infos(\n",
    "    source_infos, existing_embedding_ids, config.embed_fn_config.file_id_depth)\n",
    "\n",
    "filtered_source_infos = []\n",
    "\n",
    "for s in new_source_infos:\n",
    "    size = os.stat(s.filepath).st_size\n",
    "    if size < min_file_size:\n",
    "        continue\n",
    "    filtered_source_infos.append(s)\n",
    "\n",
    "new_source_infos = filtered_source_infos\n",
    "\n",
    "print(f'Found {len(new_source_infos)} existing embedding ids.'\n",
    "      f'Processing {len(new_source_infos)} new source infos. ')\n",
    "\n",
    "try:\n",
    "  audio_loader = lambda fp, offset: audio_utils.load_audio_window(\n",
    "      fp, offset, sample_rate=config.embed_fn_config.model_config.sample_rate,\n",
    "      window_size_s=config.get('shard_len_s', -1.0))\n",
    "  audio_iterator = audio_utils.multi_load_audio_window(\n",
    "      filepaths=[s.filepath for s in new_source_infos],\n",
    "      offsets=[s.shard_num * s.shard_len_s for s in new_source_infos],\n",
    "      audio_loader=audio_loader,\n",
    "  )\n",
    "  with tf_examples.EmbeddingsTFRecordMultiWriter(\n",
    "      output_dir=output_dir, num_files=config.get('tf_record_shards', 1)) as file_writer:\n",
    "    for source_info, audio in tqdm.tqdm(\n",
    "        zip(new_source_infos, audio_iterator), total=len(new_source_infos)):\n",
    "      file_id = source_info.file_id(config.embed_fn_config.file_id_depth)\n",
    "      offset_s = source_info.shard_num * source_info.shard_len_s\n",
    "      example = embed_fn.audio_to_example(file_id, offset_s, audio)\n",
    "      if example is None:\n",
    "        fail += 1\n",
    "        continue\n",
    "      file_writer.write(example.SerializeToString())\n",
    "      succ += 1\n",
    "    file_writer.flush()\n",
    "finally:\n",
    "  del(audio_iterator)\n",
    "print(f'\\n\\nSuccessfully processed {succ} source_infos, failed {fail} times.')\n",
    "\n",
    "fns = [fn for fn in output_dir.glob('embeddings-*')]\n",
    "ds = tf.data.TFRecordDataset(fns)\n",
    "parser = tf_examples.get_example_parser()\n",
    "ds = ds.map(parser)\n",
    "for ex in ds.as_numpy_iterator():\n",
    "  print(ex['filename'])\n",
    "  print(ex['embedding'].shape, flush=True)\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
